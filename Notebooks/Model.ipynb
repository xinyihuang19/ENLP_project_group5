{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 8140049,
     "sourceType": "datasetVersion",
     "datasetId": 4812581
    },
    {
     "sourceId": 8131539,
     "sourceType": "datasetVersion",
     "datasetId": 4806245
    }
   ],
   "dockerImageVersionId": 30698,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-22T00:26:09.556048Z",
     "iopub.execute_input": "2024-04-22T00:26:09.556894Z",
     "iopub.status.idle": "2024-04-22T00:26:29.410600Z",
     "shell.execute_reply.started": "2024-04-22T00:26:09.556857Z",
     "shell.execute_reply": "2024-04-22T00:26:29.409586Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": "2024-04-22 00:26:18.708307: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-22 00:26:18.708435: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-22 00:26:18.860293: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#####\n",
    "# Global variables\n",
    "#####\n",
    "\n",
    "# Check if CUDA can be used to speed up training/reasoning\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# CE\n",
    "# Load BERT-large tokenizer and BERT-Large model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-large-uncased').to(device)  # Make sure the model is on the correct device\n",
    "\n",
    "# Define BiGRU layer for CE\n",
    "hidden_size = 1024  # For BERT-Large，the hidden_size should be 1024\n",
    "bigru_layer = nn.GRU(input_size=1024, hidden_size=hidden_size, bidirectional=True, batch_first=True).to(device)\n",
    "\n",
    "# NE\n",
    "# Character-to-index mapping\n",
    "char_to_index = {str(i): i for i in range(10)}\n",
    "char_to_index['.'] = 10  # The index for the decimal point\n",
    "\n",
    "# Maximum numeric length and character dimension\n",
    "max_num_length = 10\n",
    "char_dim = 11\n",
    "\n",
    "# Initialize BiGRU for NE\n",
    "input_size_NE = char_dim\n",
    "hidden_size = 1024\n",
    "bigru_model = nn.GRU(input_size=input_size_NE, hidden_size=hidden_size, bidirectional=True, batch_first=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-22T00:30:48.545007Z",
     "iopub.execute_input": "2024-04-22T00:30:48.546393Z",
     "iopub.status.idle": "2024-04-22T00:31:11.360360Z",
     "shell.execute_reply.started": "2024-04-22T00:30:48.546352Z",
     "shell.execute_reply": "2024-04-22T00:31:11.359114Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbcbb542938a4f1e9434e4d41a45130a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c76a99b876649e4b520dff114211613"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "929c47b2a44c4b4884bc282cfbcdd3d0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca0569c8ae5d434393bcec2bb1fdc3fd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ce5ad59cac4425b8d0dfe1592e996e7"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Define a function to encode text using BERT and BiGRU\n",
    "def encode_with_ce(texts):\n",
    "    # Encode the texts\n",
    "    encoded_input = tokenizer(texts, return_tensors='pt',padding='max_length', truncation=True, max_length=512,\n",
    "                              add_special_tokens=True)\n",
    "\n",
    "    # Make sure the input is also on the correct device\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "\n",
    "    # Get the embedding using BERT-Large\n",
    "    with torch.no_grad():\n",
    "        output = bert_model(**encoded_input)\n",
    "\n",
    "    # The BERT model outputs a tuple, and we are interested in the first element - the hidden state\n",
    "    embeddings = output.last_hidden_state\n",
    "\n",
    "    # Pass the embed to BiGRU\n",
    "    bigru_output, _ = bigru_layer(embeddings)\n",
    "\n",
    "    return bigru_output"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-22T00:35:28.336237Z",
     "iopub.execute_input": "2024-04-22T00:35:28.337128Z",
     "iopub.status.idle": "2024-04-22T00:35:28.344690Z",
     "shell.execute_reply.started": "2024-04-22T00:35:28.337089Z",
     "shell.execute_reply": "2024-04-22T00:35:28.343427Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Convert answer's number into representations\n",
    "def encode_and_process_number(number, max_num_length=10, char_dim=11, bigru_model=bigru_model):\n",
    "    # Create an all-zero tensor\n",
    "    encoded = torch.zeros(max_num_length, char_dim)\n",
    "\n",
    "    # Calculate the left fill amount\n",
    "    padding_size = max_num_length - len(number)\n",
    "\n",
    "    # Fill encoding according to character\n",
    "    for i, char in enumerate(number):\n",
    "        if char in char_to_index:\n",
    "            encoded[padding_size + i, char_to_index[char]] = 1\n",
    "\n",
    "    # Add batch dimension\n",
    "    encoded = encoded.unsqueeze(0)  # Make the tensor shape [1, max_num_length, char_dim]\n",
    "\n",
    "    # Input the encoded tensor into BiGRU\n",
    "    bigru_output, _ = bigru_model(encoded)\n",
    "\n",
    "    # Return the output of BiGRU\n",
    "    return bigru_output"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-22T00:35:31.914574Z",
     "iopub.execute_input": "2024-04-22T00:35:31.914993Z",
     "iopub.status.idle": "2024-04-22T00:35:31.922893Z",
     "shell.execute_reply.started": "2024-04-22T00:35:31.914962Z",
     "shell.execute_reply": "2024-04-22T00:35:31.921404Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Converts the correct answer index to a unique thermal encoding\n",
    "def one_hot_encode(index, num_classes):\n",
    "    encoding = [0] * num_classes\n",
    "    encoding[index] = 1\n",
    "    return encoding"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-22T00:35:35.557267Z",
     "iopub.execute_input": "2024-04-22T00:35:35.557747Z",
     "iopub.status.idle": "2024-04-22T00:35:35.563263Z",
     "shell.execute_reply.started": "2024-04-22T00:35:35.557713Z",
     "shell.execute_reply": "2024-04-22T00:35:35.562080Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "##########\n",
    "# 1. Load the data\n",
    "##########\n",
    "\n",
    "# Import the training data\n",
    "with open('/kaggle/input/nquad-dataset/NQuAD_train_first_10k.json', 'r', encoding='utf-8') as file:\n",
    "        data_train = json.load(file)\n",
    "\n",
    "# Import the testing data\n",
    "with open('/kaggle/input/nquad-dataset/NQuAD_test_first_2k.json', 'r', encoding='utf-8') as file:\n",
    "        data_test = json.load(file)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-22T01:26:46.663531Z",
     "iopub.execute_input": "2024-04-22T01:26:46.663989Z",
     "iopub.status.idle": "2024-04-22T01:26:47.052950Z",
     "shell.execute_reply.started": "2024-04-22T01:26:46.663956Z",
     "shell.execute_reply": "2024-04-22T01:26:47.052019Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_train[0]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-22T00:52:28.915840Z",
     "iopub.execute_input": "2024-04-22T00:52:28.916309Z",
     "iopub.status.idle": "2024-04-22T00:52:28.925163Z",
     "shell.execute_reply.started": "2024-04-22T00:52:28.916280Z",
     "shell.execute_reply": "2024-04-22T00:52:28.924154Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "execution_count": 9,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'news_article': ['宏達電（2498）昨(21)日股東會上，董事長王雪紅應允小股東請求，自掏腰包贈送股東會議程結束前完成報到程序且人在會場的小股東（不含公司內部股東），每人一台宏達電旗艦手機新HTC One 32G手機、單機市價約2.19萬元，創下台灣股東會史上單價最高的贈禮。同時，宏達電董監改選，前台積電（2330）總經理蔡力行當選新任董事，被外界認為是跟台積電聯手抗韓，針對三星電子的科技競爭而進行的結盟。',\n  '據統計，當日符合條件股東數約100多位，依單機2.19萬元計算，王雪紅大手筆送給在場關心宏達電營運的小股東們逾200多萬元大禮。經過各家媒體近兩日報導，「宏達電」、「HTC」、「新HTC One」在網路上討論的熱烈程度又升高了，達到品牌與知名度的提升效果，宏達電行銷功力可謂更上層樓。',\n  '宏達電今年的股東會也全面進行董監事改選，當選董事名單包括王雪紅、陳文琦、卓火土、蔡力行、David Bruce Yoffie；獨立董事為林振國、Josef Felder；新任監察人為威智投資(股)公司、朱黃傑。',\n  '除了蔡力行是新赴任的宏達電董事外，其餘本次當選董事、監察人都為續任。',\n  '蔡力行是台積電（2330）前總經理、現任台積電太陽能與固態照明董事長；因此外界也多解讀，在台積電董事長張忠謀公開多次盛讚宏達電手機產品，並倡議聯發科（2454）、鴻海（2317）、台積電與宏達電在各自的半導體IC、面板、晶圓產業、消費性手機領域一同對付三星電子；蔡力行昨日獲選出任宏達電董事一職，可謂是台灣科技廠聯手抗韓的最新發展。'],\n 'question_stem': '王雪紅贈股東___G新One，創台股東會單價最高贈品                                                       ',\n 'answer_options': ['100', '2.19', '21', '32'],\n 'ans': 3,\n 'target_num': '32',\n 'sentences_containing_the_numeral_in_answer_options': [['當日符合條件股東數約100多位'],\n  ['單機市價約2.19萬元', '依單機2.19萬元計算'],\n  ['宏達電（2498）昨(21)日股東會上'],\n  ['每人一台宏達電旗艦手機新HTC One 32G手機']]}"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data_train[1]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-22T01:20:57.543237Z",
     "iopub.execute_input": "2024-04-22T01:20:57.543672Z",
     "iopub.status.idle": "2024-04-22T01:20:57.552330Z",
     "shell.execute_reply.started": "2024-04-22T01:20:57.543632Z",
     "shell.execute_reply": "2024-04-22T01:20:57.551007Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "execution_count": 13,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'news_article': ['印刷電板大廠燿華(2367)於今(24)日召開股東常會，會議順利結束，議程照案通過(見圖)。燿華總經理許正弘於營業報告時指出，燿華去年營運狀況不佳，但今年以來，第二季營收比第一季好，獲利也有很大的改善，第三季比第二季好，至少會有2位數的成長，目前燿華幾乎都滿載。',\n  '許正弘表示，第四季展望仍佳，但還不準，還要看消費性產品銷售狀況好不好，會再調整，許正弘表示，今年大環境景氣還是不好，但因為燿華在客戶調整以及開發，所以下半年營運成長幅度會好。',\n  '許正弘表示，目前產能還是不夠，今年資本支出至少是15億元，這15億已都下訂單，有機會再上修，主要擴充會在任意層，中長期仍要觀察中低階智慧型手機的發展以及各家品牌廠的消長。',\n  '法人預估，今年上下半年營收比重可望朝45:55分佈。',\n  '燿華回顧2012年表示，2012年的全球消費主力只有智慧型手機及平板電腦，而且更過度在少數客戶，形成供需嚴重失衡，相對削價競爭歷年來罕見。燿華雖深耕於高端HDI產品，卻因供需失序、產品售價大幅下滑，導致2012年營收及獲利大幅衰退。',\n  '燿華今股東常會順利通過財報。燿華2012年營收119.03億元，毛利率為7.6%，稅後虧損5.06億元，每股虧損0.88元。股東會通過不配發股利。'],\n 'question_stem': '燿華：Q___獲利有很大改善，Q3至少二位數成長                                                          ',\n 'answer_options': ['0.88', '2', '5.06', '7.6'],\n 'ans': 1,\n 'target_num': '2',\n 'sentences_containing_the_numeral_in_answer_options': [['每股虧損0.88元'],\n  ['至少會有2位數的成長'],\n  ['稅後虧損5.06億元'],\n  ['毛利率為7.6%']]}"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "##########\n",
    "# 2. Generate question representations for training data\n",
    "##########\n",
    "\n",
    "# Prepare training data and one-hot labels lists\n",
    "question_representations_train = []\n",
    "one_hot_labels_train = []\n",
    " \n",
    "# Iterate each sample in training data\n",
    "for sample in data_train[:2]:\n",
    "     # CE output list\n",
    "        ce_output_list = []\n",
    "     # NE output list\n",
    "        ne_output_list = []\n",
    "        \n",
    "     # 2.1 CE\n",
    "        # Process question stem\n",
    "        stem_result = encode_with_ce(sample['question_stem'])\n",
    "        ce_output_list.append(stem_result)\n",
    "        \n",
    "        # Process sentences_containing_the_numeral_in_answer_options\n",
    "        for sentence_list in sample[\"sentences_containing_the_numeral_in_answer_options\"]:\n",
    "            \n",
    "                if len(sentence_list) > 1:\n",
    "                    combined_sentence = '。'.join(sentence.strip() for sentence in sentence_list)\n",
    "                    print(combined_sentence)\n",
    "                    result = encode_with_ce(combined_sentence)\n",
    "                    ce_output_list.append(result)\n",
    "                else:\n",
    "                    print(sentence_list[0])\n",
    "                    result = encode_with_ce(sentence_list[0].strip())\n",
    "                    ce_output_list.append(result)\n",
    "        for each in ce_output_list:\n",
    "            print(each.shape)\n",
    "    \n",
    "    # 2.2 NE\n",
    "        numbers = sample[\"answer_options\"]\n",
    "        for number in numbers:\n",
    "            result = encode_and_process_number(number)\n",
    "            ne_output_list.append(result)\n",
    "        #             print(result.shape)\n",
    "        \n",
    "        for each in ne_output_list:\n",
    "            print(each.shape)\n",
    "\n",
    "    # 2.3 Concatenate\n",
    "        all_output_list = ce_output_list + ne_output_list\n",
    "        all_numpy_arrays_list = [tensor.detach().cpu().numpy() for tensor in all_output_list]\n",
    "\n",
    "        # Use tf. Keras. The layers. Concatenate to joining together all these tensor\n",
    "        concat_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "        concatenated_tensors = concat_layer(all_numpy_arrays_list)\n",
    "        print(\"concatenated_tensors.shape\")\n",
    "        print(concatenated_tensors.shape)\n",
    "\n",
    "        # 2.4 Apply global average pooling\n",
    "        global_average_layer = tf.keras.layers.GlobalAveragePooling1D()\n",
    "        pooled_tensor = global_average_layer(concatenated_tensors)\n",
    "        print(\"pooled_tensor.shape\")\n",
    "        print(pooled_tensor.shape)\n",
    "\n",
    "        # Convert it to a TensorFlow tensor\n",
    "        pooled_tensor = tf.convert_to_tensor(pooled_tensor)\n",
    "\n",
    "        # Add pooled tensor to question_representations\n",
    "        question_representations_train.append(pooled_tensor)\n",
    "\n",
    "        # 2.5 Convert index of answer into one-hot vector\n",
    "        correct_answer_index = [sample['ans']]\n",
    "        # Converts the correct answer index to TensorFlow's uniquely thermal coded tensor\n",
    "        one_hot_label = tf.one_hot(correct_answer_index, depth=4)\n",
    "        #         print(one_hot_label)\n",
    "        #         print(type(one_hot_label))\n",
    "        one_hot_labels_train.append(one_hot_label)\n",
    "        print()\n",
    "\n",
    "print(len(question_representations_train))\n",
    "print(len(one_hot_labels_train))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-22T01:31:53.429833Z",
     "iopub.execute_input": "2024-04-22T01:31:53.431040Z",
     "iopub.status.idle": "2024-04-22T01:32:29.801536Z",
     "shell.execute_reply.started": "2024-04-22T01:31:53.430999Z",
     "shell.execute_reply": "2024-04-22T01:32:29.800361Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": "當日符合條件股東數約100多位\n單機市價約2.19萬元。依單機2.19萬元計算\n宏達電（2498）昨(21)日股東會上\n每人一台宏達電旗艦手機新HTC One 32G手機\ntorch.Size([1, 512, 2048])\ntorch.Size([1, 512, 2048])\ntorch.Size([1, 512, 2048])\ntorch.Size([1, 512, 2048])\ntorch.Size([1, 512, 2048])\ntorch.Size([1, 10, 2048])\ntorch.Size([1, 10, 2048])\ntorch.Size([1, 10, 2048])\ntorch.Size([1, 10, 2048])\nconcatenated_tensors.shape\n(1, 2600, 2048)\npooled_tensor.shape\n(1, 2048)\n\n每股虧損0.88元\n至少會有2位數的成長\n稅後虧損5.06億元\n毛利率為7.6%\ntorch.Size([1, 512, 2048])\ntorch.Size([1, 512, 2048])\ntorch.Size([1, 512, 2048])\ntorch.Size([1, 512, 2048])\ntorch.Size([1, 512, 2048])\ntorch.Size([1, 10, 2048])\ntorch.Size([1, 10, 2048])\ntorch.Size([1, 10, 2048])\ntorch.Size([1, 10, 2048])\nconcatenated_tensors.shape\n(1, 2600, 2048)\npooled_tensor.shape\n(1, 2048)\n\n2\n2\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data_test[0]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-22T01:26:52.151437Z",
     "iopub.execute_input": "2024-04-22T01:26:52.152394Z",
     "iopub.status.idle": "2024-04-22T01:26:52.159786Z",
     "shell.execute_reply.started": "2024-04-22T01:26:52.152358Z",
     "shell.execute_reply": "2024-04-22T01:26:52.158648Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": [
    {
     "execution_count": 16,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'news_article': ['日本蘋果情報網站iPhone Mania 23日報導，據調查公司IHS Markit公布的統計資料顯示，2016年全球最暢銷(出貨量最多)的智慧手機產品不是蘋果(Apple)去年9月推出的iPhone 7、而是前一世代的iPhone 6s，iPhone 7排第2；去年全球前10大暢銷智慧手機產品中，iPhone包辦前4名，除iPhone 6s、iPhone 7之外，iPhone 7 Plus、iPhone 6s Plus分居第3、4位。',\n  '若單就上季(2016年10-12月)情況來看，全球最暢銷機種為iPhone 7，iPhone 7 Plus排第2。',\n  '在蘋果死對頭三星電子的部分，旗艦機種Galaxy Note 7雖因連環爆而召回停售，不過因三星積極進行促銷活動、包含套裝販售可和Galaxy智慧手機連接使用的虛擬實境(VR)裝置Gear VR，故在前10大暢銷機種中、三星Galaxy產品拿下5個席次，其中Galaxy S7 Edge、Galaxy S7分居第5、9位。Galaxy S7/S7 Edge去年全球出貨量較前一代機種(Galaxy S6/S6 Edge)多出1,000萬支。',\n  '另外，華為雖為全球第3大智慧手機廠，不過因採機海策略、推出各種價格帶的機種，故未能有1款產品擠進前10大行列。',\n  'OPPO推出的OPPO A53位居第7位，是前10大暢銷機種中唯一一款非蘋果、三星的機種，且表現優於三星S7。OPPO去年全球智慧手機出貨量暴增109%，市佔排名從2015年的第7位躍升至第4位。',\n  '據全球市場研究機構TrendForce公布的資料顯示，2016年全球智慧型手機出貨量為13.6億支，年成長4.7%。其中三星以22.8%的市佔率位居首位，其次分別為蘋果的15.3%、華為的9.6%、OPPO的7.2%、BBK/VIVO的6.0%、LG的5.5%、小米的3.7%、聯想的3.7%、TCL的3.7%和中興通訊(ZTE)的3.5%。',\n  '＊編者按：本文僅供參考之用，並不構成要約、招攬或邀請、誘使、任何不論種類或形式之申述或訂立任何建議及推薦，讀者務請運用個人獨立思考能力，自行作出投資決定，如因相關建議招致損失，概與《精實財經媒體》、編者及作者無涉。'],\n 'question_stem': 'iPhone 6s為全球最暢銷智慧機；OPPO A53勝過三星S___                                               ',\n 'answer_options': ['6', '6.0', '7', '7.2'],\n 'ans': 2,\n 'target_num': '7',\n 'sentences_containing_the_numeral_in_answer_options': [['而是前一世代的iPhone 6s',\n   '除iPhone 6s',\n   'iPhone 6s Plus分居第3',\n   'Galaxy S7/S7 Edge去年全球出貨量較前一代機種(Galaxy S6/S6 Edge)多出1,000萬支'],\n  ['BBK/VIVO的6.0%'],\n  ['2016年全球最暢銷(出貨量最多)的智慧手機產品不是蘋果(Apple)去年9月推出的iPhone 7',\n   'iPhone 7排第2',\n   'iPhone 7之外',\n   'iPhone 7 Plus',\n   '全球最暢銷機種為iPhone 7',\n   'iPhone 7 Plus排第2',\n   '旗艦機種Galaxy Note 7雖因連環爆而召回停售',\n   '其中Galaxy S7 Edge',\n   'Galaxy S7分居第5',\n   'Galaxy S7/S7 Edge去年全球出貨量較前一代機種(Galaxy S6/S6 Edge)多出1,000萬支',\n   'OPPO推出的OPPO A53位居第7位',\n   '且表現優於三星S7',\n   '市佔排名從2015年的第7位躍升至第4位'],\n  ['OPPO的7.2%']]}"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "##########\n",
    "# 3. Make MLP model and put question representations and one-hot label list into MLP model\n",
    "##########\n",
    "\n",
    "# Construct a MLP model\n",
    "mlp = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(2048,)),\n",
    "        tf.keras.layers.Dropout(0.3),  # Add dropout\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "mlp.fit(question_representations_train, one_hot_labels_train, epochs=10, batch_size=32)\n",
    "\n",
    "#####\n",
    "# 4. Prepare testing data and make predictions\n",
    "#####\n",
    "\n",
    "# Prepare training data and one-hot labels lists\n",
    "question_representations_test = []\n",
    "one_hot_labels_test = []\n",
    "\n",
    "# Iterate each sample in training data\n",
    "for sample in data_test[:1]:\n",
    "     # CE output list\n",
    "        ce_output_list = []\n",
    "     # NE output list\n",
    "        ne_output_list = []\n",
    "        \n",
    "     # 2.1 CE\n",
    "        # Process question stem\n",
    "        stem_result = encode_with_ce(sample['question_stem'])\n",
    "        ce_output_list.append(stem_result)\n",
    "        \n",
    "        # Process sentences_containing_the_numeral_in_answer_options\n",
    "        for sentence_list in sample[\"sentences_containing_the_numeral_in_answer_options\"]:\n",
    "                if len(sentence_list) > 1:\n",
    "                    combined_sentence = '。'.join(sentence.strip() for sentence in sentence_list)\n",
    "                    print(combined_sentence)\n",
    "                    result = encode_with_ce(combined_sentence)\n",
    "                    ce_output_list.append(result)\n",
    "                else:\n",
    "                    print(sentence_list[0])\n",
    "                    result = encode_with_ce(sentence_list[0].strip())\n",
    "                    ce_output_list.append(result)\n",
    "        for each in ce_output_list:\n",
    "            print(each.shape)\n",
    "    \n",
    "    # 2.2 NE\n",
    "        numbers = sample[\"answer_options\"]\n",
    "        for number in numbers:\n",
    "            result = encode_and_process_number(number)\n",
    "            ne_output_list.append(result)\n",
    "        #             print(result.shape)\n",
    "        \n",
    "        for each in ne_output_list:\n",
    "            print(each.shape)\n",
    "\n",
    "    # 2.3 Concatenate\n",
    "        all_output_list = ce_output_list + ne_output_list\n",
    "        all_numpy_arrays_list = [tensor.detach().cpu().numpy() for tensor in all_output_list]\n",
    "\n",
    "        # Use tf. Keras. The layers. Concatenate to joining together all these tensor\n",
    "        concat_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "        concatenated_tensors = concat_layer(all_numpy_arrays_list)\n",
    "        print(\"concatenated_tensors.shape\")\n",
    "        print(concatenated_tensors.shape)\n",
    "\n",
    "        # 2.4 Apply global average pooling\n",
    "        global_average_layer = tf.keras.layers.GlobalAveragePooling1D()\n",
    "        pooled_tensor = global_average_layer(concatenated_tensors)\n",
    "        print(\"pooled_tensor.shape\")\n",
    "        print(pooled_tensor.shape)\n",
    "\n",
    "        # Convert it to a TensorFlow tensor\n",
    "        pooled_tensor = tf.convert_to_tensor(pooled_tensor)\n",
    "\n",
    "        # Add pooled tensor to question_representations\n",
    "        question_representations_test.append(pooled_tensor)\n",
    "\n",
    "        # 2.5 Convert index of answer into one-hot vector\n",
    "        correct_answer_index = [sample['ans']]\n",
    "        # Converts the correct answer index to TensorFlow's uniquely thermal coded tensor\n",
    "        one_hot_label = tf.one_hot(correct_answer_index, depth=4)\n",
    "        #         print(one_hot_label)\n",
    "        #         print(type(one_hot_label))\n",
    "        one_hot_labels_test.append(one_hot_label)\n",
    "        print()\n",
    "\n",
    "print(len(question_representations_test))\n",
    "print(len(one_hot_labels_test))\n",
    "\n",
    "# Evaluate the model\n",
    "# Evaluate the model using the test set data question_representations_test and one_hot_labels_test\n",
    "loss, accuracy = mlp.evaluate(question_representations_test, one_hot_labels_test)\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-22T01:33:37.770062Z",
     "iopub.execute_input": "2024-04-22T01:33:37.771034Z",
     "iopub.status.idle": "2024-04-22T01:33:58.277873Z",
     "shell.execute_reply.started": "2024-04-22T01:33:37.770997Z",
     "shell.execute_reply": "2024-04-22T01:33:58.276839Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/10\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1s/step - accuracy: 0.0000e+00 - loss: 1.2536\nEpoch 2/10\n\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 1.0000 - loss: 0.7425\nEpoch 3/10\n\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 0.3804\nEpoch 4/10\n\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 1.0000 - loss: 0.1426\nEpoch 5/10\n\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 1.0000 - loss: 0.0678\nEpoch 6/10\n\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 1.0000 - loss: 0.0303\nEpoch 7/10\n\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 1.0000 - loss: 0.0164\nEpoch 8/10\n\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 1.0000 - loss: 0.0023\nEpoch 9/10\n\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 1.0000 - loss: 0.0064\nEpoch 10/10\n\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 0.0011\n而是前一世代的iPhone 6s。除iPhone 6s。iPhone 6s Plus分居第3。Galaxy S7/S7 Edge去年全球出貨量較前一代機種(Galaxy S6/S6 Edge)多出1,000萬支\nBBK/VIVO的6.0%\n2016年全球最暢銷(出貨量最多)的智慧手機產品不是蘋果(Apple)去年9月推出的iPhone 7。iPhone 7排第2。iPhone 7之外。iPhone 7 Plus。全球最暢銷機種為iPhone 7。iPhone 7 Plus排第2。旗艦機種Galaxy Note 7雖因連環爆而召回停售。其中Galaxy S7 Edge。Galaxy S7分居第5。Galaxy S7/S7 Edge去年全球出貨量較前一代機種(Galaxy S6/S6 Edge)多出1,000萬支。OPPO推出的OPPO A53位居第7位。且表現優於三星S7。市佔排名從2015年的第7位躍升至第4位\nOPPO的7.2%\ntorch.Size([1, 512, 2048])\ntorch.Size([1, 512, 2048])\ntorch.Size([1, 512, 2048])\ntorch.Size([1, 512, 2048])\ntorch.Size([1, 512, 2048])\ntorch.Size([1, 10, 2048])\ntorch.Size([1, 10, 2048])\ntorch.Size([1, 10, 2048])\ntorch.Size([1, 10, 2048])\nconcatenated_tensors.shape\n(1, 2600, 2048)\npooled_tensor.shape\n(1, 2048)\n\n1\n1\n\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 192ms/step - accuracy: 0.0000e+00 - loss: 6.4055\nLoss: 6.405498027801514\nAccuracy: 0.0\n",
     "output_type": "stream"
    }
   ]
  }
 ]
}
